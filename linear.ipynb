{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled22.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohanrajmit/Linear_Classification/blob/master/linear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "SD4UWsRxRiKJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6bsgA8JeRlIg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initialize the class labels and set the seed of the pseudorandom\n",
        "# number generator so we can reproduce our results\n",
        "labels = [\"dog\", \"cat\", \"panda\"]\n",
        "np.random.seed(5)\n",
        "\n",
        "# randomly initialize our weight matrix and bias vector -- in a\n",
        "# *real* training and classification task, these parameters would\n",
        "# be *learned* by our model, but for the sake of this example,\n",
        "# let's use random values\n",
        "W = np.random.randn(3, 3072)\n",
        "b = np.random.randn(3)\n",
        "\n",
        "# load our example image, resize it, and then flatten it into our\n",
        "# \"feature vector\" representation\n",
        "orig = cv2.imread(\"beagle.png\")\n",
        "image = cv2.resize(orig, (32, 32)).flatten()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kgnrw0ktRnQe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# compute the output scores by taking the dot product between the\n",
        "# weight matrix and image pixels, followed by adding in the bias\n",
        "scores = W.dot(image) + b\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ADvuEeQuRs8G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loop over the scores + labels and display them\n",
        "for (label, score) in zip(labels, scores):\n",
        "\tprint(\"[INFO] {}: {:.2f}\".format(label, score))\n",
        "\n",
        "# draw the label with the highest score on the image as our\n",
        "# prediction\n",
        "cv2.putText(orig, \"Label: {}\".format(labels[np.argmax(scores)]),\n",
        "\t(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KaJwSXm8R4YQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "plt.imshow(orig)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}